# Changelog

All notable changes to the Torale project will be documented in this file.

## [0.2.0] - 2025-06-27 - Milestone 1: Discovery Service Extraction

### üéâ Major Features Added

**Discovery Microservice**
- ‚úÖ Standalone discovery service (`discovery-service/`) running on port 8001
- ‚úÖ Natural language ‚Üí URL discovery using Perplexity API
- ‚úÖ RESTful API: `POST /api/v1/discover` with structured JSON responses
- ‚úÖ Health check endpoint for monitoring and load balancing
- ‚úÖ Structured logging with detailed telemetry
- ‚úÖ Docker containerization support

**Backend Integration**  
- ‚úÖ HTTP client for discovery service communication (`backend/app/clients/discovery_client.py`)
- ‚úÖ Automatic service detection with fallback to legacy AI models
- ‚úÖ Configuration-driven microservice usage (`DISCOVERY_SERVICE_URL`)
- ‚úÖ Proper error handling (503 Service Unavailable for service downtime)

**Development Experience**
- ‚úÖ Simplified flat folder structure (no nested `app/` directories)
- ‚úÖ Multi-service startup script (`start-microservices.sh`)
- ‚úÖ Docker Compose orchestration for local development
- ‚úÖ Comprehensive deployment documentation

### üîß Technical Improvements

**AI Integration Fixes**
- Fixed Perplexity API model name from `sonar-medium-online` to `sonar`
- Improved prompt engineering for better URL extraction
- Added regex-based URL parsing from AI responses
- Enhanced error handling and retry logic

**Architecture Benefits Achieved**
- Independent service deployment and scaling
- Service isolation with fault tolerance
- Technology flexibility (FastAPI + Perplexity vs FastAPI + OpenAI)
- Development team autonomy

### üìÅ Files Added

**New Microservice**
- `discovery-service/` - Complete standalone discovery service
- `discovery-service/main.py` - FastAPI application entry point
- `discovery-service/api/discovery.py` - Discovery API endpoints
- `discovery-service/clients/perplexity_client.py` - Perplexity API integration
- `discovery-service/clients/openai_client.py` - OpenAI API integration (fallback)
- `discovery-service/services/discovery_service.py` - Core business logic
- `discovery-service/config.py` - Service configuration
- `discovery-service/dependencies.py` - Dependency injection
- `discovery-service/Dockerfile` - Container build configuration
- `discovery-service/pyproject.toml` - Python project configuration
- `discovery-service/.env.example` - Environment variable template

**Backend Integration**
- `backend/app/clients/discovery_client.py` - HTTP client for discovery service

**Documentation & Tooling**
- `MILESTONE-1-SUCCESS.md` - Detailed milestone completion report
- `discovery-service/README.md` - Service documentation
- `discovery-service/DEPLOYMENT.md` - Deployment guide
- `start-microservices.sh` - Multi-service development script
- `test-discovery.sh` - Discovery service testing script
- `docker-compose.yml` - Multi-service orchestration

### üìù Files Modified

**Configuration Updates**
- `backend/app/core/config.py` - Added `DISCOVERY_SERVICE_URL` setting
- `backend/app/services/source_discovery_service.py` - Microservice integration
- `backend/app/api/deps.py` - Updated dependency injection
- `backend/app/api/endpoints/source_discovery.py` - Service integration
- `backend/.env.example` - Added microservice configuration

**Documentation Updates**
- `README.md` - Updated with microservices architecture information
- `architecture-plan.md` - Detailed migration plan (previously created)

### üéØ Performance & Reliability

**Service Performance**
- Service startup time: ~2 seconds
- Average query processing: 3-4 seconds (AI API dependent)
- Memory footprint: ~50MB per service instance
- Horizontal scaling ready (stateless design)

**Error Handling**
- Graceful degradation when discovery service unavailable
- Comprehensive error logging and monitoring
- Service health checks for load balancer integration
- Automatic fallback to legacy AI model approach

### üöÄ Deployment Ready

**Local Development**
```bash
# Microservices mode
./start-microservices.sh

# Legacy mode  
./start.sh
```

**Production Deployment**
- Docker containerization complete
- Environment variable configuration
- Health check endpoints configured
- Multi-platform deployment documentation

### ‚ö° What's Next: Milestone 2

**Notification Service Extraction**
- Extract email notification logic to dedicated service
- Multi-channel support (email, webhooks, future SMS/Slack)
- Template management and delivery tracking
- Async message queue integration

---

## [0.1.0] - Previous Release

Initial monolithic application with authentication, monitoring, and alerting features.